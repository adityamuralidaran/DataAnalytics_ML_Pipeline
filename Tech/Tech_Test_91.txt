“You are going to have a chance to play with Alexa,” I told my daughter, Grace, who’s 3 years old. Pointing at the black cylindrical device, I explained that the speaker, also known as the Amazon Echo, was a bit like Siri but smarter. “You can ask it anything you want,” I said nonchalantly. 
Grace leaned forward toward the speaker. “Hello, Alexa, my name is Gracie,” she said. “Will it rain today?” The turquoise rim glowed into life. “Currently, it is 60 degrees,” a perky female voice answered, assuring her it wouldn’t rain.
Over the next hour, Grace figured out she could ask Alexa to play her favorite music from the film “Sing.” She realized Alexa could tell jokes, do math or provide interesting facts. “Hey, Alexa, what do brown horses eat?” And she soon discovered a whole new level of power. “Alexa, shut up,” she barked, then looked a little sheepish and asked me if it was O.K. to be rude to her. So she thought the speaker had feelings?
By the next morning, Alexa was the first “person” Grace said hello to as she bounded into the kitchen wearing her pink fluffy dressing gown. My preschooler who can’t yet ride a bike or read a book had also quickly mastered that she could buy things with the bot’s help, or at least try to.
“Alexa, buy me blueberries,” she commanded. Grace, of course, had no idea that Amazon, the world’s biggest retailer, was the corporate behemoth behind the helpful female assistant, and that smoothing the way when it came to impulse buys was right up Alexa’s algorithmic alley.
Grace’s easy embrace of Alexa was slightly amusing but also alarming. My small experiment, with my daughter as the guinea pig, drove home to me the profound shift in our relationship with technology. For generations, our trust in it has gone no further than feeling confident the machine or mechanism will do what it’s supposed or expected to do, nothing more, nothing less. We trust a washing machine to clean our clothes or an A.T.M. to dispense money, but we don’t expect to form a relationship with them or call them by name.
Today, we’re no longer trusting machines just to do something, but to decide what to do and when to do it. The next generation will grow up in an age where it’s normal to be surrounded by autonomous agents, with or without cute names. The Alexas of the world will make a raft of decisions for my kids and others like them as they proceed through life — everything from whether to have mac and cheese or a green bowl for dinner to the perfect gift for a friend’s birthday to what to do to improve their mood or energy and even advice on whom they should date. In time, the question for them won’t be, “Should we trust robots?” but “Do we trust them too much?”
With some trepidation, I watched my daughter gaily hand her decisions over. “Alexa, what should I do today?” Grace asked in her singsong voice on Day 3. It wasn’t long before she was trusting her with the big choices. “Alexa, what should I wear today? My pink or my sparkly dress?”
In April, Amazon unveiled the Echo Look, a $199 Alexa add-on that features a hands-free selfie camera controlled by your voice. The device doesn’t just hear you, it sees you. According to Amazon, the Style Check feature uses “machine-learning algorithms with advice from fashion specialists” to judge different outfits, awarding them an overall rating to decide which is “better” based on “current trends and what flatters you.”
The images it takes of you happen to be stored in the Amazon Web Services cloud until you delete them. And while the fashion-savvy assistant helps you decide what to wear, it has an ulterior motive: to sell you clothing, including choices from one of Amazon’s own apparel lines, such as Lark & Ro and North Eleven, started in 2016.
It’s these kinds of intersections – like this small collision between robot “helpfulness” and a latent commercial agenda — that can make parents like me start to wonder about the ethical niceties of this brave new bot world. Alexa, after all, is not “Alexa.” She’s a corporate algorithm in a black box.

Grace doesn’t like it when I tell her what to wear. How would she feel about Alexa judging her? Would she see it as helpful or crushing? This could well be one of our parenting tasks in the near future — preparing our children for the psychological repercussions of such personal interactions with computer “people.”
Still, the next generation is likely to feel very differently about machines than we do. In a study conducted by M.I.T. Media Lab, 27 children, aged between 3 and 10, interacted with A.I. devices and toys including Alexa, Google Home, Julie (a chatbot) and, finally, Cozmo (a robot in the form of a toy bulldozer). The researchers asked the children how they felt about the devices in terms of intelligence, personality and trust. The younger children seemed to see the agents as real people and asked them personal questions: “Hey, Alexa, how old are you?” and “What are you?” Some thought the device had multiple personalities. “She doesn’t know the answer,” said one child, wisely. “Ask the other Alexa.”
Almost 80 percent of the children thought Alexa would always tell the truth. Some of the children believed they could teach the devices something useful, like how to make a paper plane, suggesting they felt a genuine, give-and-take relationship with the machines.
How do we teach our children to question not only the security and privacy implications but also the ethical and commercial intentions of a device designed by marketers?
Our kids are going to need to know where and when it is appropriate to put their trust in computer code alone. I watched Grace hand over her trust to Alexa quickly. There are few checks and balances to deter children from doing just that, not to mention very few tools to help them make informed decisions about A.I. advice. And isn’t helping Gracie learn how to make decisions about what to wear — and many more even important things in life — my job? I decided to retire Alexa to the closet.
