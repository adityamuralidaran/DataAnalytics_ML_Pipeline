WASHINGTON — Thousands of Google employees, including dozens of senior engineers, have signed a letter protesting the company’s involvement in a Pentagon program that uses artificial intelligence to interpret video imagery and could be used to improve the targeting of drone strikes.
The letter, which is circulating inside Google and has garnered more than 3,100 signatures, reflects a culture clash between Silicon Valley and the federal government that is likely to intensify as cutting-edge artificial intelligence is increasingly employed for military purposes.
(Read the text of the letter.)
“We believe that Google should not be in the business of war,” says the letter, addressed to Sundar Pichai, the company’s chief executive. It asks that Google pull out of Project Maven, a Pentagon pilot program, and announce a policy that it will not “ever build warfare technology.”
That kind of idealistic stance, while certainly not shared by all Google employees, comes naturally to a company whose motto is “Don’t be evil,” a phrase invoked in the protest letter. But it is distinctly foreign to Washington’s massive defense industry and certainly to the Pentagon, where the defense secretary, Jim Mattis, has often said a central goal is to increase the “lethality” of the United States military.
From its early days, Google has encouraged employees to speak out on issues involving the company. It provides internal message boards and social networks where workers challenge management and one another about the company’s products and policies. Recently, the heated debate around Google’s efforts to create a more diverse work force spilled out into the open.
Google employees have circulated protest petitions on a range of issues, including Google Plus, the company’s lagging competitor to Facebook, and Google’s sponsorship of the Conservative Political Action Conference.
Employees raised questions about Google’s involvement in Project Maven at a recent companywide meeting. At the time, Diane Greene, who leads Google’s cloud infrastructure business, defended the deal and sought to reassure concerned employees. A company spokesman said most of the signatures on the protest letter had been collected before the company had an opportunity to explain the situation.
The company subsequently described its work on Project Maven as “non-offensive” in nature, though the Pentagon’s video analysis is routinely used in counterinsurgency and counterterrorism operations, and Defense Department publications make clear that the project supports those operations. Both Google and the Pentagon said the company’s products would not create an autonomous weapons system that could fire without a human operator, a much-debated possibility using artificial intelligence.
But improved analysis of drone video could be used to pick out human targets for strikes, while also better identifying civilians to reduce the accidental killing of innocent people.
Without referring directly to the letter to Mr. Pichai, Google said in a statement on Tuesday that “any military use of machine learning naturally raises valid concerns.” It added, “We’re actively engaged across the company in a comprehensive discussion of this important topic.” The company called such exchanges “hugely important and beneficial,” though several Google employees familiar with the letter would speak of it only on the condition of anonymity, saying they were concerned about retaliation.
The statement said the company’s part of Project Maven was “specifically scoped to be for non-offensive purposes,” though officials declined to make available the relevant contract language. The Defense Department said that because Google is a subcontractor on Project Maven to the prime contractor, ECS Federal, it could not provide either the amount or the language of Google’s contract. ECS Federal did not respond to inquiries.
Google said the Pentagon was using “open-source object recognition software available to any Google Cloud customer” and based on unclassified data. “The technology is used to flag images for human review and is intended to save lives and save people from having to do highly tedious work,” the company said.
Some of Google’s top executives have significant Pentagon connections. Eric Schmidt, former executive chairman of Google and still a member of the executive board of Alphabet, Google’s parent company, serves on a Pentagon advisory body, the Defense Innovation Board, as does a Google vice president, Milo Medin.
In an interview in November, Mr. Schmidt acknowledged “a general concern in the tech community of somehow the military-industrial complex using their stuff to kill people incorrectly, if you will.” He said he served on the board in part “to at least allow for communications to occur” and suggested that the military would “use this technology to help keep the country safe.”
An uneasiness about military contracts among a small fraction of Google’s more than 70,000 employees may not pose a major obstacle to the company’s growth. But in the rarefied area of artificial intelligence research, Google is engaged in intense competition with other tech companies for the most talented people, so recruiters could be hampered if some candidates are put off by Google’s defense connections.
As Google defends its contracts from internal dissent, its competitors have not been shy about publicizing their own work on defense projects. Amazon touts its image recognition work with the Department of Defense, and Microsoft has promoted the fact that its cloud technology won a contract to handle classified information for every branch of the military and defense agencies.
The current dispute, first reported by Gizmodo, is focused on Project Maven, which began last year as a pilot program to find ways to speed up the military application of the latest A.I. technology. It is expected to cost less than $70 million in its first year, according to a Pentagon spokeswoman. But the signers of the letter at Google clearly hope to discourage the company from entering into far larger Pentagon contracts as the defense applications of artificial intelligence grow.
Google is widely expected to compete with other tech giants, including Amazon and Microsoft, for a multiyear, multibillion-dollar contract to provide cloud services to the Defense Department. John Gibson, the department’s chief management officer, said last month that the Joint Enterprise Defense Infrastructure Cloud procurement program was in part designed to “increase lethality and readiness,” underscoring the difficulty of separating software, cloud and related services from the actual business of war.
The employees’ protest letter to Mr. Pichai, which has been circulated on an internal communications system for several weeks, argues that embracing military work could backfire by alienating customers and potential recruits.
“This plan will irreparably damage Google’s brand and its ability to compete for talent,” the letter says. “Amid growing fears of biased and weaponized AI, Google is already struggling to keep the public’s trust.” It suggests that Google risks being viewed as joining the ranks of big defense contractors like Raytheon, General Dynamics and the big-data firm Palantir.
“The argument that other firms, like Microsoft and Amazon, are also participating doesn’t make this any less risky for Google,” the letter says. “Google’s unique history, its motto Don’t Be Evil, and its direct reach into the lives of billions of users set it apart.”
Like other onetime upstarts turned powerful Silicon Valley behemoths, Google is being forced to confront the idealism that guided the company in its early years. Facebook started with the lofty mission of connecting people all over the world, but it has recently come under fire for becoming a conduit for fake news and being used by Russia to influence the 2016 election and sow dissent among American voters.
Paul Scharre, a former Pentagon official and author of “Army of None,” a forthcoming book on the use of artificial intelligence to build autonomous weapons, said the clash inside Google was inevitable, given the company’s history and the booming demand for A.I. in the military.
“There’s a strong libertarian ethos among tech folks, and a wariness about the government’s use of technology,” said Mr. Scharre, a senior fellow at the Center for a New American Security in Washington. “Now A.I. is suddenly and quite quickly moving out of the research lab and into real life.”
